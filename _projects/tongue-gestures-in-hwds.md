---
title: "Tongue Gestures in Head Worn Devices"
excerpt: "Tongue gestures are an accessible and subtle method for interacting with wearables but past studies have used custom hardware with a single sensing modality. At Microsoft Research, I used multimodal sensors in a commercial VR headset and EEG headband to build a 50,000 gesture dataset and real-time classifier. I also invented a new interaction method combining tongue and gaze to enable faster gaze-based selection in hands-free interactions."
teaser: "/images/tonguegestures.png"
date: "2022-08-12"
collection: projects
category: research
tags: [ sensing, head-worn-displays, subtle-interaction ]
links:
- [UbiComp poster, paper, https://tangemicioglu.com/publications/#tongue-gestures-for-hands-free-interaction-in-head-worn-displays/]
- [talk, video, https://www.microsoft.com/en-us/research/video/tongue-gesture-recognition-in-head-mounted-displays/]
---

Pioneered a new, accessible method of hands-free interaction with head-worn displays using tongue gestures, detected using multimodal sensing capabilities in current VR headsets. Collected a multi-location, multi-sensor dataset of 50,000 gestures across 16 participants.