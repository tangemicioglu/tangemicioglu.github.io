---
title: "Tongue Gestures in Head Worn Devices"
excerpt: "Tongue gestures are an accessible and subtle method for interacting with wearables but past studies have used custom hardware with a single sensing modality. At Microsoft Research, I used multimodal sensors in a commercial VR headset and EEG headband to build a 50,000 gesture dataset and real-time classifier. I also invented a new interaction method combining tongue and gaze to enable faster gaze-based selection in hands-free interactions."
teaser: "/images/tonguegestures.png"
date: "2022-08-12"
collection: projects
categories: research
tags: [ sensing, head-worn-displays, subtle-interaction ]
---

Pioneered a new, accessible method of hands-free interaction with head-worn displays using tongue gestures, detected using multimodal sensing capabilities in current VR headsets. Collected a multi-location, multi-sensor dataset of 50,000 gestures across 16 participants.