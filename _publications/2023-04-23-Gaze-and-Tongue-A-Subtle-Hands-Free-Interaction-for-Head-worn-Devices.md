---
title: "Gaze & Tongue: A Subtle Hands-Free Interaction for Head-worn Devices"
teaser: "/images/tongue-games.png"
date: "2023-09-11"
collection: publications
authors: "<b>Tan Gemicioglu</b>, R. Michael Winters, Yu-Te Wang, Thomas M. Gable, Ann Paradiso, Ivan J. Tashev"
venue: "Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems"
abstract: "Gaze tracking allows hands-free and voice-free interaction with computers, and has gained more use recently in virtual and augmented reality headsets. However, it traditionally uses dwell time for selection tasks, which suffers from the Midas Touch problem. Tongue gestures are subtle, accessible and can be sensed non-intrusively using an IMU at the back of the ear, PPG and EEG. We demonstrate a novel interaction method combining gaze tracking with tongue gestures for gaze-based selection faster than dwell time and multiple selection options. We showcase its usage as a point-and-click interface in three hands-free games and a musical instrument."
link: "/files/papers/Tongue_Gestures_CHI_2023_Interactivity.pdf"
category: demo
tags: [sensing, subtle-interaction, gaze, gesture]
links:
- [doi, doi, https://doi.org/10.1145/3544549.3583930]
- [paper, pdf, /files/papers/Tongue_Gestures_CHI_2023_Interactivity.pdf]
- [Best Demo Finalist, award, https://chi2023.acm.org/for-authors/interactivity/]
---